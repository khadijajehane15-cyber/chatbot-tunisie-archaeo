import streamlit as st
import chromadb
from sentence_transformers import SentenceTransformer
import ollama
import time

# Configuration
st.set_page_config(
    page_title="Chatbot Arch√©ologie Tunisie",
    page_icon="üèõÔ∏è",
    layout="wide"
)

# Cache pour optimiser
@st.cache_resource
def load_models():
    """Charge les mod√®les une fois"""
    # Mod√®le d'embedding
    embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
    
    # Connexion ChromaDB
    client = chromadb.PersistentClient(path="./chroma_db")
    collection = client.get_collection("sites_archeo_tunisie")
    
    return embedding_model, collection

def search_documents(question, top_k=3):
    """Recherche les documents pertinents"""
    embedding_model, collection = load_models()
    
    # Cr√©er l'embedding
    question_embedding = embedding_model.encode(question).tolist()
    
    # Rechercher
    results = collection.query(
        query_embeddings=[question_embedding],
        n_results=top_k
    )
    
    return results

def generate_response(question, context_results):
    """G√©n√®re une r√©ponse avec gemma3:1b"""
    if not context_results['documents'][0]:
        return "Je ne trouve pas d'information sur ce sujet dans ma base de donn√©es.", []
    
    docs = context_results['documents'][0]
    metas = context_results['metadatas'][0]
    
    # Construire le contexte
    contexte = ""
    for i, (doc, meta) in enumerate(zip(docs, metas)):
        contexte += f"\n[Source {i+1} - {meta['site']}]\n{doc[:400]}\n"
    
    # Prompt optimis√© pour gemma3:1b
    prompt = f"""Tu es un expert en arch√©ologie tunisienne.

CONTEXTE :{contexte}

QUESTION : {question}

R√©ponds en fran√ßais en utilisant uniquement le contexte ci-dessus.
Sois pr√©cis et cite tes sources : [Source X - Site]"""

    try:
        # G√©n√©rer avec gemma3:1b
        response = ollama.chat(
            model='gemma3:1b',
            messages=[{'role': 'user', 'content': prompt}],
            options={
                'num_gpu': 0,      # CPU seulement
                'temperature': 0.1, # Tr√®s factuel
                'num_predict': 200  # R√©ponse courte
            }
        )
        
        return response['message']['content'], metas
        
    except Exception as e:
        # Fallback simple
        st.error(f"Erreur avec le mod√®le : {str(e)[:100]}")
        if docs:
            return f"D'apr√®s {metas[0]['site']} : {docs[0][:200]}...", metas
        return "Erreur de g√©n√©ration.", []

def main():
    """Interface principale"""
    
    # Sidebar
    with st.sidebar:
        st.title("üèõÔ∏è Information")
        st.markdown("""
        **Chatbot RAG - Sites Arch√©ologiques de Tunisie**
        
        **Technologie :**
        - Mod√®le : **gemma3:1b** (l√©ger et rapide)
        - Base : **ChromaDB** avec 50+ documents
        - Recherche : **RAG** (Retrieval-Augmented Generation)
        
        **Sites disponibles (10) :**
        - Carthage, Dougga, El Jem, Kerkouane
        - Bulla Regia, Sbeitla, Utique
        - Thuburbo Majus, Makthar, Chemtou
        """)
        
        st.markdown("---")
        st.markdown("**Exemples de questions :**")
        st.markdown("- O√π se trouve Carthage ?")
        st.markdown("- Quelle est la capacit√© du th√©√¢tre de Dougga ?")
        st.markdown("- Quelle est la particularit√© de Kerkouane ?")
        st.markdown("- Quels sites sont class√©s UNESCO ?")
        
        st.markdown("---")
        # Statistiques
        try:
            _, collection = load_models()
            count = collection.count()
            st.markdown(f"**üìä Statistiques :**")
            st.markdown(f"- Chunks dans la base : **{count}**")
            st.markdown(f"- Mod√®le : **gemma3:1b**")
        except:
            pass
    
    # Zone principale
    st.title("üèõÔ∏è Chatbot des Sites Arch√©ologiques de Tunisie")
    st.markdown("Posez vos questions sur les 10 sites arch√©ologiques tunisiens")
    
    # Initialiser l'historique
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    # Afficher l'historique
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            
            if "sources" in message and message["sources"]:
                with st.expander("üìö Voir les sources"):
                    for source in message["sources"]:
                        st.markdown(f"‚Ä¢ {source}")
    
    # Zone de saisie
    if prompt := st.chat_input("Posez votre question ici..."):
        # Ajouter la question √† l'historique
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        # Afficher la question
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # Afficher un indicateur de chargement
        with st.chat_message("assistant"):
            with st.spinner("Recherche dans 50 documents..."):
                # Rechercher les documents
                search_results = search_documents(prompt)
                
                # G√©n√©rer la r√©ponse
                start_time = time.time()
                response, sources_meta = generate_response(prompt, search_results)
                elapsed_time = time.time() - start_time
                
                # Afficher la r√©ponse
                st.markdown(response)
                
                # Afficher les sources
                if sources_meta:
                    with st.expander(f"üìö Sources utilis√©es ({len(sources_meta)})"):
                        for i, meta in enumerate(sources_meta):
                            st.markdown(f"{i+1}. **{meta['site']}** - *{meta['document']}*")
                    
                    # Pr√©parer pour l'historique
                    sources_list = [f"{meta['site']} ({meta['document']})" for meta in sources_meta]
                else:
                    sources_list = []
                
                # Afficher le temps
                st.caption(f"‚è±Ô∏è G√©n√©r√© en {elapsed_time:.1f} secondes")
        
        # Ajouter la r√©ponse √† l'historique
        st.session_state.messages.append({
            "role": "assistant", 
            "content": response,
            "sources": sources_list
        })
    
    # Bouton pour effacer
    if st.sidebar.button("üßπ Effacer l'historique"):
        st.session_state.messages = []
        st.rerun()

if __name__ == "__main__":
    main()