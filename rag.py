import chromadb
from sentence_transformers import SentenceTransformer
import ollama
import sys

class RAGChatbot:
    def __init__(self):
        """
        Initialise le chatbot RAG avec gemma3:1b
        """
        print("ü§ñ Initialisation du chatbot RAG...")
        
        # 1. Charger le mod√®le d'embedding
        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
        print("‚úÖ Mod√®le d'embedding charg√©")
        
        # 2. Se connecter √† ChromaDB
        self.chroma_client = chromadb.PersistentClient(path="./chroma_db")
        self.collection = self.chroma_client.get_collection("sites_archeo_tunisie")
        print("‚úÖ Base de donn√©es ChromaDB connect√©e")
        
        # 3. V√©rifier le mod√®le gemma3:1b
        print("üîç V√©rification du mod√®le gemma3:1b...")
        try:
            models = ollama.list()
            model_names = [m['name'] for m in models['models']]
            
            if 'gemma3:1b' in model_names:
                print("‚úÖ gemma3:1b disponible")
            else:
                print("‚ö†Ô∏è  gemma3:1b non trouv√©")
                print("   T√©l√©charge avec: ollama pull gemma3:1b")
                
        except Exception as e:
            print(f"‚ö†Ô∏è  Erreur Ollama: {str(e)[:50]}")
        
        print("üöÄ Chatbot RAG pr√™t !")
        print("-" * 40)
    
    def search_in_chromadb(self, question, top_k=3):
        """
        Recherche les documents pertinents dans ChromaDB
        """
        # Cr√©er l'embedding de la question
        question_embedding = self.embedding_model.encode(question).tolist()
        
        # Rechercher dans ChromaDB
        results = self.collection.query(
            query_embeddings=[question_embedding],
            n_results=top_k
        )
        
        return results
    
    def build_prompt(self, question, search_results):
        """
        Construit le prompt pour le LLM
        """
        # Extraire les documents et m√©tadonn√©es
        documents = search_results['documents'][0]
        metadatas = search_results['metadatas'][0]
        
        # Construire le contexte
        context_parts = []
        for i, (doc, meta) in enumerate(zip(documents, metadatas)):
            context_parts.append(f"[Source {i+1}: {meta['site']}]")
            context_parts.append(doc[:500])  # Limiter la longueur
            context_parts.append("")
        
        context = "\n".join(context_parts)
        
        # Prompt optimis√© pour gemma3:1b
        prompt = f"""Tu es un expert en arch√©ologie tunisienne.

INFORMATIONS DISPONIBLES:
{context}

QUESTION: {question}

INSTRUCTIONS:
1. R√©ponds en fran√ßais
2. Utilise UNIQUEMENT les informations ci-dessus
3. Sois pr√©cis et factuel
4. Cite tes sources comme [Source X]
5. Si l'information n'est pas disponible, dis-le clairement

R√âPONSE:"""
        
        return prompt, metadatas
    
    def generate_answer(self, prompt):
        """
        G√©n√®re une r√©ponse avec gemma3:1b via Ollama
        """
        try:
            # Appeler gemma3:1b avec options CPU
            response = ollama.chat(
                model='gemma3:1b',
                messages=[
                    {
                        'role': 'user',
                        'content': prompt
                    }
                ],
                options={
                    'num_gpu': 0,      # Force CPU
                    'temperature': 0.1, # Faible cr√©ativit√©
                    'num_predict': 200  # R√©ponse courte
                }
            )
            
            return response['message']['content']
            
        except Exception as e:
            return f"‚ùå Erreur avec le mod√®le : {str(e)[:100]}"
    
    def ask_question(self, question):
        """
        Pose une question au chatbot
        """
        print(f"\n‚ùì Question : {question}")
        print("üîç Recherche dans la base de donn√©es...")
        
        # 1. Rechercher dans ChromaDB
        search_results = self.search_in_chromadb(question, top_k=3)
        
        # V√©rifier si on a des r√©sultats
        if not search_results['documents'][0]:
            return "Je ne trouve pas d'information sur ce sujet dans ma base de donn√©es.", []
        
        # 2. Construire le prompt
        prompt, metadatas = self.build_prompt(question, search_results)
        
        # 3. G√©n√©rer la r√©ponse
        print("üß† G√©n√©ration de la r√©ponse avec gemma3:1b...")
        answer = self.generate_answer(prompt)
        
        # 4. Pr√©parer les sources
        sources = []
        for i, meta in enumerate(metadatas):
            sources.append(f"{i+1}. {meta['site']} - {meta['document']}")
        
        return answer, sources
    
    def chat_loop(self):
        """
        Boucle de chat interactive
        """
        print("\n" + "="*50)
        print("üí¨ CHATBOT RAG - SITES ARCH√âOLOGIQUES TUNISIENS")
        print("="*50)
        print("Mod√®le : gemma3:1b (l√©ger et rapide)")
        print("Commandes : 'quit'=quitter, 'sources'=liste")
        print("-"*50)
        
        while True:
            # Poser une question
            question = input("\nüëâ Pose ta question : ").strip()
            
            # Commandes sp√©ciales
            if question.lower() in ['quit', 'exit', 'q']:
                print("üëã Au revoir !")
                break
                
            elif question.lower() == 'sources':
                print("\nüìö Sources disponibles :")
                count = self.collection.count()
                print(f"   {count} chunks dans la base de donn√©es")
                
                # Compter les sites uniques
                all_docs = self.collection.get()
                if all_docs and 'metadatas' in all_docs:
                    sites = set()
                    for meta in all_docs['metadatas']:
                        if meta and 'site' in meta:
                            sites.add(meta['site'])
                    print(f"   Sites : {', '.join(sorted(sites))}")
                continue
            
            elif not question:
                continue
            
            # G√©n√©rer une r√©ponse
            try:
                answer, sources = self.ask_question(question)
                
                print("\nü§ñ R√âPONSE :")
                print("-" * 40)
                print(answer)
                print("-" * 40)
                
                if sources:
                    print("\nüìö SOURCES :")
                    for source in sources:
                        print(f"   ‚Ä¢ {source}")
                    
            except Exception as e:
                print(f"‚ùå Erreur : {e}")

def main():
    """
    Fonction principale
    """
    # Cr√©er le chatbot
    chatbot = RAGChatbot()
    
    # D√©marrer la boucle de chat
    chatbot.chat_loop()

# Ex√©cuter le script si appel√© directement
if __name__ == "__main__":
    main()